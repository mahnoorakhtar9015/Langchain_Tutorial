{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPONENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPEN_AI_KEY']=\"open ai key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage,AIMessage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat=ChatOpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Since you like mangoes, you might enjoy a tropical fruit salad with mangoes, pineapples, and kiwis. Another option could be mango sticky rice, a popular Thai dessert. You could also try a mango smoothie or a mango salsa to add a sweet and tangy flavor to your meal. Enjoy your mango-inspired dish!', response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 37, 'total_tokens': 105}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0e739e9e-3fdd-4c98-af3a-4f9435c93c82-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "\n",
    "    [\n",
    "    SystemMessage(content=\"You are a nice AI bot that helps a user to figure out what to eat\"),\n",
    "    HumanMessage(content=\"I like mangoes,what should I eat?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOCUMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='This is the content of pages', metadata={'my_document_id': 1, 'my_document_source': 'Mahnoor Papers', 'my_document_create_time': 7102024})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Document(\n",
    "    page_content=\"This is the content of pages\",\n",
    "    metadata={\n",
    "        'my_document_id':1,\n",
    "        'my_document_source':\"Mahnoor Papers\",\n",
    "        'my_document_create_time':7102024\n",
    "\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LANGUAGE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSaturday'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm=OpenAI(temperature=0)\n",
    "\n",
    "\n",
    "llm(\"What comes after friday?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHAT MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage,AIMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat=ChatOpenAI(temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Have you tried banging your head against the wall? It might not help with the headache, but at least you'll have a different reason to be in pain!\", response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 34, 'total_tokens': 66}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-43df2b4e-fec7-45da-b208-2c741083dacd-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are an unhelpful AI that makes joke of everything user says\"),\n",
    "        HumanMessage(content=\"What I should I do when I have headache\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEXT EMBEDDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embedding=OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "text=\"Hi, its time to get the results\"\n",
    "\n",
    "text_embedding=embedding.embed_query(text)\n",
    "\n",
    "print(len(text_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The issue with that statement is that it skips over Tuesday. The correct statement would be \"Today is Monday and Tomorrow is Tuesday.\"'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm=OpenAI(temperature=0.2)\n",
    "\n",
    "prompt=\"\"\"\n",
    "Today is Monday and Tomorrow is wednesday\n",
    "\n",
    "What is the issue with that statement?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "llm(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE SELECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI()\n",
    "example_prompt= PromptTemplate(\n",
    "    input_variables=['input','output'],\n",
    "    template=\"Example input : {input} /n Example output : {output}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=[\n",
    "    {'input':'bird' , 'output':'nest'},\n",
    "    {'input':'tree' , 'output':'ground'},\n",
    "    {'input':'pilot' , 'output':'plane'},\n",
    "    {'input':'pirate' , 'output':'ship'},\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector=SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    OpenAIEmbeddings(),\n",
    "    FAISS,\n",
    "    k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt=FewShotPromptTemplate(\n",
    "     example_selector=example_selector,\n",
    "     example_prompt=example_prompt,\n",
    "\n",
    "     prefix='Give the location an item is usually found in',\n",
    "     suffix=\"Input:{noun}\\nOutput:\",\n",
    "     input_variables=[\"noun\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the location an item is usually found in\n",
      "\n",
      "Example input : tree /n Example output : ground\n",
      "\n",
      "Example input : bird /n Example output : nest\n",
      "\n",
      "Input:flower\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "mynoun=\"flower\"\n",
    "\n",
    "print(similar_prompt.format(noun=mynoun))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garden\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(llm(similar_prompt.format(noun=mynoun)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OUTPUT PARSER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas=[\n",
    "    ResponseSchema(name='bad string' , description=\"This is poorly formatted user string\"),\n",
    "    ResponseSchema(name='Good string', description=\"This is your string, reformatted string\")\n",
    "]\n",
    "\n",
    "output_parser=StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad string\": string  // This is poorly formatted user string\n",
      "\t\"Good string\": string  // This is your string, reformatted string\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions=output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "You will be given with poorly formatted user string.\n",
    "Reformate it and make sure all the words are spelled correctly.\n",
    "\n",
    "{format_instructions}\n",
    "User input:\n",
    "{user_input}\n",
    "\n",
    "User Response:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    input_variables=['user_input'],\n",
    "    partial_variables={\"format_instructions\":format_instructions},   \n",
    "    template=template\n",
    ")\n",
    "\n",
    "\n",
    "input_prompt=prompt.format(user_input=\"Wlcm to Pakstan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"bad string\": \"Wlcm to Pakstan\", \n",
      "\t\"Good string\": \"Welcome to Pakistan\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(llm(input_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad string': 'Wlcm to Pakstan', 'Good string': 'Welcome to Pakistan'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(llm(input_prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOCUMENT LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HNLoader\n",
    "loader=HNLoader(\"https://news.ycombinator.com\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
